{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock Price Movement Prediction - Best variation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNg7d0xNkyMz",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAPKCxwUkqwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install yfinance\n",
        "!pip install mpl_finance\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9miQ7h0kxgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import date\n",
        "import yfinance as yf\n",
        "from mpl_finance import candlestick2_ochl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import load_model, save_model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Flatten, Activation, add\n",
        "from keras.layers import Dropout, Flatten, LeakyReLU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras import initializers\n",
        "from keras.engine import Layer, InputSpec\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam, rmsprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzkQA5mrk10D",
        "colab_type": "text"
      },
      "source": [
        "# Core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWuP42L-lJkE",
        "colab_type": "text"
      },
      "source": [
        "in this part, we will find the best model, timestep, and timegap\n",
        "\n",
        "> **timestep** is the number of candlestick that we use as the input for the model<br>\n",
        "<br>\n",
        "> **timegap** is the number of day for the movement to be predicted<br>\n",
        "eq : if timestep is 14, we will predict the movement of stock price (up or down) 14 days from today<br>\n",
        "<br>\n",
        "> **model** is the variation of convolutional neural network. in this notebook, we variate the filter size and the number of convolution layer and pooling in pair.<br><br>\n",
        "https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
        "<br>by : Sumit Saha. <br>for the explanation of Convolutional Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OOjxBNKoFMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make function to call the variation of convolution\n",
        "def model(model_name):\n",
        "    if (model_name == 'model 1')|(model_name == 'model 3'):\n",
        "        filter_size = 3\n",
        "    elif (model_name == 'model 2')|(model_name == 'model 4'):\n",
        "        filter_size = 5\n",
        "    else:\n",
        "        TypeError('not recognized model')\n",
        "\n",
        "    # Input\n",
        "    input_layer = Input(shape=(100,100,3))\n",
        "    # First Convolution + Pooling\n",
        "    x = Conv2D(32, filter_size, filter_size, activation='relu')(input_layer)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    # Second Convolution + Pooling\n",
        "    x = Conv2D(48, filter_size, filter_size, activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    # Third Convolution + Pooling\n",
        "    x = Conv2D(64, filter_size, filter_size, activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    # Fourth Convolution + Pooling (Optional)\n",
        "    if (model_name == 'model 3')|(model_name == 'model 4'):\n",
        "        x = Conv2D(96, filter_size, filter_size, activation='relu')(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    # Fully Connected\n",
        "    x = Dense(output_dim=256, activation='relu')(x)\n",
        "    x = Dense(output_dim=1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(input_layer, x)\n",
        "\n",
        "    model.compile(optimizer=rmsprop(lr=1.0e-4),loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcaPW-pWkjzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine the Stock we want\n",
        "stock = 'BMRI.JK'\n",
        "data = yf.download(stock,'2000-01-01','2020-12-31')\n",
        "data = data.reset_index()\n",
        "data['Year'] = [data.loc[i,'Date'].year for i in range(data.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82UQvJKDkqFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the year that we want to use (may be variate)\n",
        "year = [2016,2017,2018,2019,2020]\n",
        "train = data[[data.loc[j,'Year'] in year for j in range(data.shape[0])]]\n",
        "train = train.reset_index().drop('index',axis = 1)\n",
        "\n",
        "# we use the last year data as the testing data and save the number of data in this variable\n",
        "n_test_day = train[train['Year']==year[-1]].shape[0]\n",
        "\n",
        "# use dark background to make the background value into 0 after we change the candlestick image into pixel RGB representation\n",
        "plt.style.use('dark_background')\n",
        "train_temp_x = []\n",
        "train_temp_y = []\n",
        "\n",
        "# we will iterave the variation \n",
        "for timestep in [20,40,60]:\n",
        "    for timegap in [1,7,14]:\n",
        "        for k in range(0,train.shape[0]-timestep-timegap):\n",
        "            c = train.loc[k:k + int(timestep) -1, :]\n",
        "            if len(c) == int(timestep):\n",
        "                my_dpi = 96\n",
        "                fig = plt.figure(figsize=(100 / my_dpi,\n",
        "                                            100 / my_dpi), dpi=my_dpi)\n",
        "                ax = fig.add_subplot(1, 1, 1)\n",
        "                # convert tabular data into image\n",
        "                candlestick2_ochl(ax, c['Open'], c['Close'], c['High'],\n",
        "                                    c['Low'], width=0.85,\n",
        "                                    colorup='#77d879', colordown='#db3f3f', alpha = 1)\n",
        "                ax.axis('off')\n",
        "                fig.canvas.draw()\n",
        "                # conver image into RGB representation\n",
        "                temp_temp_x = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
        "                plt.close();\n",
        "                clear_output()\n",
        "                temp_temp_x = (temp_temp_x.reshape(fig.canvas.get_width_height()[::-1] + (3,))/255).tolist()\n",
        "                train_temp_x.append(temp_temp_x)\n",
        "                train_temp_y.append([1 if train.loc[k+timestep-1+timegap,'Close'] - train.loc[k+timestep-1, 'Close']>=0 else 0])\n",
        "\n",
        "        # split the data for training and validation\n",
        "        tx = np.array(train_temp_x)[:-n_test_day]\n",
        "        ex = np.array(train_temp_x)[-n_test_day:]\n",
        "        ty = np.array(train_temp_y)[:-n_test_day]\n",
        "        ey = np.array(train_temp_y)[-n_test_day:]\n",
        "\n",
        "        # iterate the model\n",
        "        for models in ['model 1','model 2','model 3','model 4']:\n",
        "            cnn_model = model_cnn(models)\n",
        "            nn_history = cnn_model.fit(tx,ty, epochs = 100, batch_size = 100, validation_data=[ex,ey])\n",
        "            print('\\n accuracy train {} and accuracy test {}'.format(np.array(nn_history.history['accuracy'][-10:]).mean(),\n",
        "                                                                np.array(nn_history.history['val_accuracy'][-10:]).mean()))\n",
        "            # we will save the result\n",
        "            #pd.DataFrame(nn_history.history).to_csv('Hasil/Hasil_potong_potong/timestep{}_timegap{}_{}_{}_periode{}{}.csv'.format(timestep,timegap,models,stock,year[0],year[-1]))\n",
        "            print('timestep{}_timegap{}_{}_{}_periode{}{}.csv'.format(timestep,timegap,models,stock,year[0],year[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}